{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10408010,"sourceType":"datasetVersion","datasetId":5211395}],"dockerImageVersionId":30097,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! git clone https://github.com/t1hachane/nckh_2025","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:25:09.743311Z","iopub.execute_input":"2025-02-09T13:25:09.743660Z","iopub.status.idle":"2025-02-09T13:25:13.021878Z","shell.execute_reply.started":"2025-02-09T13:25:09.743627Z","shell.execute_reply":"2025-02-09T13:25:13.021082Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'nckh_2025'...\nremote: Enumerating objects: 160, done.\u001b[K\nremote: Counting objects: 100% (47/47), done.\u001b[K\nremote: Compressing objects: 100% (33/33), done.\u001b[K\nremote: Total 160 (delta 27), reused 34 (delta 14), pack-reused 113 (from 1)\u001b[K\nReceiving objects: 100% (160/160), 72.19 MiB | 47.91 MiB/s, done.\nResolving deltas: 100% (88/88), done.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"%cd '/kaggle/working/nckh_2025/xai'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:25:13.023447Z","iopub.execute_input":"2025-02-09T13:25:13.023711Z","iopub.status.idle":"2025-02-09T13:25:13.028958Z","shell.execute_reply.started":"2025-02-09T13:25:13.023682Z","shell.execute_reply":"2025-02-09T13:25:13.027982Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/nckh_2025/xai\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"! git pull origin main","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:25:13.030515Z","iopub.execute_input":"2025-02-09T13:25:13.030799Z","iopub.status.idle":"2025-02-09T13:25:14.255329Z","shell.execute_reply.started":"2025-02-09T13:25:13.030774Z","shell.execute_reply":"2025-02-09T13:25:14.254215Z"}},"outputs":[{"name":"stdout","text":"From https://github.com/t1hachane/nckh_2025\n * branch            main       -> FETCH_HEAD\nAlready up to date.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"# 0. Imports","metadata":{}},{"cell_type":"code","source":"dataset_name = 'tcga-gbm-methxgexcnv-2000-3-omics'\nCOHORT = 'TCGA_GBM_GExCNVxMETH_2000_MinMaxScaler'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:25:14.257657Z","iopub.execute_input":"2025-02-09T13:25:14.258039Z","iopub.status.idle":"2025-02-09T13:25:14.262594Z","shell.execute_reply.started":"2025-02-09T13:25:14.257991Z","shell.execute_reply":"2025-02-09T13:25:14.261647Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"## Phase 1","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport os\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import display, HTML\n!pip install watermark --quiet\nimport random\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (\n    classification_report,\n    confusion_matrix,\n    ConfusionMatrixDisplay,\n    accuracy_score,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:25:14.264113Z","iopub.execute_input":"2025-02-09T13:25:14.264506Z","iopub.status.idle":"2025-02-09T13:25:19.860717Z","shell.execute_reply.started":"2025-02-09T13:25:14.264465Z","shell.execute_reply":"2025-02-09T13:25:19.859467Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# tmp = f'/kaggle/input/{dataset_name}'\n# %cd {tmp}\n%cd '/kaggle/working/nckh_2025/xai'\nfrom models import init_model_dict\nfrom utils import load_model_dict\nfrom train_test import prepare_trte_data, gen_trte_adj_mat, test_epoch\n\nfrom train_test import train_test\nfrom train_test import gen_trte_adj_mat\nfrom utils import save_model_dict\n\n# %cd '/kaggle/working'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:25:19.862264Z","iopub.execute_input":"2025-02-09T13:25:19.862549Z","iopub.status.idle":"2025-02-09T13:25:19.868778Z","shell.execute_reply.started":"2025-02-09T13:25:19.862517Z","shell.execute_reply":"2025-02-09T13:25:19.867893Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/nckh_2025/xai\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"## Phase 2","metadata":{}},{"cell_type":"code","source":"from scipy.stats import mode\nfrom datetime import datetime\n\n!pip install captum --quiet\nfrom captum.attr import IntegratedGradients, GradientShap","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:25:19.870048Z","iopub.execute_input":"2025-02-09T13:25:19.870331Z","iopub.status.idle":"2025-02-09T13:25:25.452727Z","shell.execute_reply.started":"2025-02-09T13:25:19.870305Z","shell.execute_reply":"2025-02-09T13:25:25.451648Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"## Phase 3","metadata":{}},{"cell_type":"code","source":"import sklearn\nfrom sklearn.metrics import f1_score, accuracy_score, roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\nimport copy\nfrom sklearn.compose import ColumnTransformer \nfrom IPython.display import Markdown\n\nimport warnings\nfrom sklearn.exceptions import ConvergenceWarning","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:25:25.454419Z","iopub.execute_input":"2025-02-09T13:25:25.454721Z","iopub.status.idle":"2025-02-09T13:25:25.460525Z","shell.execute_reply.started":"2025-02-09T13:25:25.454690Z","shell.execute_reply":"2025-02-09T13:25:25.459469Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"# 1.0. Hyperparameters","metadata":{}},{"cell_type":"code","source":"cuda = True if torch.cuda.is_available() else False\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f'cuda: {cuda}')\n%load_ext watermark\n%watermark -a 'Le Hoang' -u -d -v -p torch,numpy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:25:25.463720Z","iopub.execute_input":"2025-02-09T13:25:25.463968Z","iopub.status.idle":"2025-02-09T13:25:25.516534Z","shell.execute_reply.started":"2025-02-09T13:25:25.463944Z","shell.execute_reply":"2025-02-09T13:25:25.515563Z"}},"outputs":[{"name":"stdout","text":"cuda: True\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nAuthor: Le Hoang\n\nLast updated: 2025-02-09\n\nPython implementation: CPython\nPython version       : 3.7.10\nIPython version      : 7.22.0\n\ntorch: 1.7.0\nnumpy: 1.19.5\n\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"def set_seed(seed: int = 42) -> None:\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    print(f\"Random seed set as {seed}\")\n\n# Config\nrseed = 42\nset_seed(rseed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:25:25.518846Z","iopub.execute_input":"2025-02-09T13:25:25.519202Z","iopub.status.idle":"2025-02-09T13:25:25.525545Z","shell.execute_reply.started":"2025-02-09T13:25:25.519160Z","shell.execute_reply":"2025-02-09T13:25:25.524582Z"}},"outputs":[{"name":"stdout","text":"Random seed set as 42\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"postfix_tr = '_tr'\npostfix_te = '_val'\n\ndata_folder = f'/kaggle/input/{dataset_name}/{COHORT}'\nmodel_folder = '/kaggle/working/models'\ntrain_file = f'/kaggle/working/nckh_2025/xai/main_mmd.py'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:25:25.526905Z","iopub.execute_input":"2025-02-09T13:25:25.527251Z","iopub.status.idle":"2025-02-09T13:25:25.535857Z","shell.execute_reply.started":"2025-02-09T13:25:25.527216Z","shell.execute_reply":"2025-02-09T13:25:25.535067Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# Subtypes\nloc_file_json_id_omic = data_folder + '/1/dct_index_subtype.json'\nwith open(loc_file_json_id_omic) as file_json_id_omic:\n    dct_LABEL_MAPPING_NAME = json.load(file_json_id_omic)\n    # dct_LABEL_MAPPING_NAME = {int(k): v for k,v in dct_LABEL_MAPPING_NAME.items()} # convert str number key to int\nLABEL_MAPPING_NAME = dct_LABEL_MAPPING_NAME.values()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:25:25.536936Z","iopub.execute_input":"2025-02-09T13:25:25.537204Z","iopub.status.idle":"2025-02-09T13:25:25.549424Z","shell.execute_reply.started":"2025-02-09T13:25:25.537171Z","shell.execute_reply":"2025-02-09T13:25:25.548716Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"num_models=4\nidx_list = list(range(1,num_models+1))\nview_list = [1,2,3]\n\n# Hyperparameters\nnum_epoch= 1500\n# lr_e = 1e-4\nlr = 1e-4\n# dim_he_list=[250,300,150]\nhidden_dim = [1000]\npatience=200\nverbose = False\n\nretrain=True\nbool_using_early_stopping = True\nverbose = False\nprint_hyper = True\nRun_MMD = True\ntestonly = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:25:25.550627Z","iopub.execute_input":"2025-02-09T13:25:25.550965Z","iopub.status.idle":"2025-02-09T13:25:25.557117Z","shell.execute_reply.started":"2025-02-09T13:25:25.550930Z","shell.execute_reply":"2025-02-09T13:25:25.556357Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# Check data size\nfor fold_id in [3]:\n#     print(f'idx data: {fold_id}')\n    tmp = list(LABEL_MAPPING_NAME)\n    label_files = ['tr', 'te', 'val']\n    dict = {\n        'tr': 'Train set',\n        'te': 'Test set',\n        'val': 'Validation set'\n    }\n    \n    print('\\nCount per Subtypes: \\n')\n    for label_file in label_files:\n        df = pd.read_csv(f'{data_folder}/{fold_id}/labels_{label_file}.csv', header=None, names=['subtypes'])\n        subtype_counts = df['subtypes'].value_counts().sort_index()\n        \n        print(f'{dict[label_file]}')\n        \n        res = {}\n        for subtype, count in subtype_counts.items():\n            res[tmp[subtype]] = count\n\n        print(pd.DataFrame(res, index=[0]).to_string(index=False), '\\n')\n    \n    print('\\nCount Samples: \\n')\n    for idx in view_list:\n        res = {}\n        for label_file in label_files:\n            df = pd.read_csv(f'{data_folder}/{fold_id}/{idx}_{label_file}.csv', header=None)\n            res[dict[label_file]] = df.shape[0]\n            \n        print(pd.DataFrame(res, index=[0]).to_string(index=False), '\\n')\n    \n    print('\\nCount Features: \\n')\n    res={}\n    for idx in view_list:\n        df = pd.read_csv(f'{data_folder}/{fold_id}/{idx}_featname.csv', header=None, names=['featname'])\n        res[f\"Omic {idx}\"] = df.shape[0]\n        \n    print(pd.DataFrame(res, index=[0]).to_string(index=False), '\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:25:25.558458Z","iopub.execute_input":"2025-02-09T13:25:25.558843Z","iopub.status.idle":"2025-02-09T13:25:26.607008Z","shell.execute_reply.started":"2025-02-09T13:25:25.558797Z","shell.execute_reply":"2025-02-09T13:25:26.606029Z"}},"outputs":[{"name":"stdout","text":"\nCount per Subtypes: \n\nTrain set\n Classical  Mesenchymal  Neural  Proneural\n        43           48      28         43 \n\nTest set\n Classical  Mesenchymal  Neural  Proneural\n        14           16       9         15 \n\nValidation set\n Classical  Mesenchymal  Neural  Proneural\n        14           17       9         14 \n\n\nCount Samples: \n\n Train set  Test set  Validation set\n       162        54              54 \n\n Train set  Test set  Validation set\n       162        54              54 \n\n Train set  Test set  Validation set\n       162        54              54 \n\n\nCount Features: \n\n Omic 1  Omic 2  Omic 3\n   2000    2000    2000 \n\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"num_view = len(view_list)\nnum_class = len(LABEL_MAPPING_NAME)\nif num_class == 2:\n    adj_parameter = 2\n    dim_he_list = [200,200,100]\nif num_class > 2:\n    adj_parameter = 10\n#     dim_he_list = [400,400,200]\ndim_hvcdn= pow(num_class,num_view)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:25:26.608393Z","iopub.execute_input":"2025-02-09T13:25:26.608713Z","iopub.status.idle":"2025-02-09T13:25:26.613322Z","shell.execute_reply.started":"2025-02-09T13:25:26.608683Z","shell.execute_reply":"2025-02-09T13:25:26.612358Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"added_softmax = False\n\n# Prepairing raw data\ndef preprocessing_data(tup_tensor_test_data, data_folder):\n    data_tr_list = []\n    data_te_list = []\n#     print(view_list)\n\n    for i in view_list:\n        data_tr_list.append(torch.tensor(np.loadtxt(os.path.join(data_folder, str(i)+\"_tr.csv\"), delimiter=','),dtype=torch.float32))\n        data_te_list.append(tup_tensor_test_data[i-1])\n        if cuda:\n            data_tr_list[i-1] = data_tr_list[i-1].to(device)\n            data_te_list[i-1] = data_te_list[i-1].to(device)       \n\n    # num train's records, test's records\n    num_tr = data_tr_list[0].shape[0]\n    num_te = data_te_list[0].shape[0]\n\n    # idx\n    trte_idx = {}\n    trte_idx[\"tr\"] = list(range(num_tr))\n    trte_idx[\"te\"] = list(range(num_tr, (num_tr+num_te)))\n\n    # num of views or num of omics\n    num_view = len(view_list)\n    data_tensor_list = []\n    for i in range(num_view):\n        data_tensor_list.append(torch.cat((data_tr_list[i], data_te_list[i]), axis=0))\n        if cuda:\n            data_tensor_list[i] = data_tensor_list[i].to(device)#cuda()\n    \n    data_train_list = []\n    data_trte_list = []\n    for i in range(len(data_tensor_list)):\n        data_train_list.append(data_tensor_list[i][trte_idx[\"tr\"]].clone())\n\n        tup_seq_data = (data_tensor_list[i][trte_idx[\"tr\"]].clone(), data_tensor_list[i][trte_idx[\"te\"]].clone())\n        data_trte_list.append(\n            torch.cat(tup_seq_data,axis=0)\n        )\n    return data_train_list, data_trte_list,trte_idx\n\n\n# III. For Feature Important\n\ndef custom_logit_predictor(*tup_tensor_data, data_folder):\n    # Set softmax flag\n    global added_softmax\n    added_softmax = True\n\n    # Move model to device\n    if cuda:\n        model_dict['MMDynamic'].to(device)\n    model_dict['MMDynamic'].eval()\n\n    # Process input tensors\n    tup_tensor_data = tuple(tensor_data.to(device) if cuda else tensor_data \n                           for tensor_data in tup_tensor_data)\n\n    # Preprocess data\n    data_tr_list, data_trte_list, trte_idx = preprocessing_data(tup_tensor_data, data_folder)\n\n    # Get predictions using MMDynamic model\n    with torch.set_grad_enabled(True):\n        predictions = model_dict['MMDynamic'].infer(data_trte_list)\n\n    # Get test predictions\n    predictions = predictions[trte_idx[\"te\"],:]\n\n    # Apply softmax\n    if added_softmax:\n        predictions = F.softmax(predictions, dim=1)\n\n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:25:26.614440Z","iopub.execute_input":"2025-02-09T13:25:26.614714Z","iopub.status.idle":"2025-02-09T13:25:26.627960Z","shell.execute_reply.started":"2025-02-09T13:25:26.614688Z","shell.execute_reply":"2025-02-09T13:25:26.626856Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"model_dict=None\ndef load_model(data_folder, model_folder):\n    # ---- load paper's model1\n    data_tr_list, data_trte_list, trte_idx, labels_trte = prepare_trte_data(data_folder, view_list, postfix_tr='_tr', postfix_te='_val')\n    dim_list = [x.shape[1] for x in data_tr_list]\n\n    global model_dict\n    model_dict = init_model_dict(num_class, dim_list, hidden_dim)\n\n    model_dict = load_model_dict(model_folder, model_dict)\n    # ---- Done","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:25:26.629230Z","iopub.execute_input":"2025-02-09T13:25:26.629533Z","iopub.status.idle":"2025-02-09T13:25:26.642788Z","shell.execute_reply.started":"2025-02-09T13:25:26.629503Z","shell.execute_reply":"2025-02-09T13:25:26.641833Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"def display_classification_report(\n    n_class,\n    conf_matrix,\n    avg_report,\n    label_mapping_name,\n    cmap=\"Blues\",\n    fmt=\".2%\",\n    annot=True,\n    path=None,  # str path to save fig. If not None\n    shown=True,\n):\n    clf_df = avg_report\n    clf_df.loc[[\"precision\", \"recall\"], \"accuracy\"] = np.nan\n\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    fig.set_figwidth(12)\n    \n    ConfusionMatrixDisplay(conf_matrix, display_labels=label_mapping_name).plot(cmap=cmap, ax=ax1)\n    \n    sns.heatmap(clf_df.iloc[:-1, :].T, annot=annot, cmap=cmap, robust=True, ax=ax2, fmt=fmt)\n    \n    if path is not None:\n        fig.savefig(path, dpi=300)\n    if shown:\n        plt.show()\n    else:\n        plt.close(fig)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:25:26.644136Z","iopub.execute_input":"2025-02-09T13:25:26.644415Z","iopub.status.idle":"2025-02-09T13:25:26.656521Z","shell.execute_reply.started":"2025-02-09T13:25:26.644387Z","shell.execute_reply":"2025-02-09T13:25:26.655516Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"def calculate_average_report(reports):\n    \"\"\"Calculate the average classification report from a list of reports.\"\"\"\n    avg_report = pd.DataFrame(reports[0]).copy()\n    for report in reports[1:]:\n        avg_report += pd.DataFrame(report)\n    avg_report /= len(reports)\n    return avg_report\n\ndef evaluate_model(bool_report=True, _type_data='te'):\n    conf_matrix = np.zeros((num_class, num_class), dtype=int)\n\n    reports = []\n    results = []\n\n    for idx in idx_list:\n        cur_model_folder = f'{model_folder}/{idx}'\n        cur_data_folder = f\"{data_folder}/{idx}/\"\n        load_model(cur_data_folder, cur_model_folder)\n\n        _data_list = []\n\n        _label = np.loadtxt(os.path.join(cur_data_folder, f\"labels_{_type_data}.csv\"), delimiter=',').astype(int)\n\n        for i in view_list:\n            _data_loc = os.path.join(cur_data_folder, f\"{i}_{_type_data}.csv\")\n            _data_list.append(np.loadtxt(_data_loc, delimiter=','))\n        \n        _tensor_data_list = tuple(torch.tensor(np_arr, dtype=torch.float32).to(device) for np_arr in _data_list)\n        pred = custom_logit_predictor(*_tensor_data_list, data_folder=cur_data_folder)\n        pred = np.array(torch.argmax(pred.cpu(), dim=1))\n\n        fold_conf_matrix = confusion_matrix(_label, pred, labels=np.arange(num_class))\n        conf_matrix += fold_conf_matrix\n        \n        acc = accuracy_score(_label, pred)\n        f1_macro = f1_score(_label, pred, average='macro')\n        f1_weighted = f1_score(_label, pred, average='weighted')\n        results.append((idx, acc, f1_macro, f1_weighted))\n\n        # Get classification report for the current fold\n        report = classification_report(_label, pred, target_names=LABEL_MAPPING_NAME, output_dict=True)\n        reports.append(report)\n\n    if bool_report:\n        if not os.path.exists(\"/kaggle/working/phase1\"):\n            os.makedirs(\"/kaggle/working/phase1\")\n        \n        # Calculate average classification report\n        avg_report = calculate_average_report(reports)\n        \n        # Calculate the average of the models\n        df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'F1 Macro', 'F1 Weighted'])\n        avg_row = ['Average', df['Accuracy'].mean(), df['F1 Macro'].mean(), df['F1 Weighted'].mean()]\n        df.loc[len(df)] = avg_row\n\n        print(df.to_string(index=False))\n\n        # Display confusion matrix and classification report\n        display_classification_report(\n            num_class,\n            conf_matrix,\n            avg_report,\n            LABEL_MAPPING_NAME,\n            path=f\"/kaggle/working/phase1/Evaluate_model_{_type_data}\",\n        )\n\n    return avg_report['macro avg']['f1-score']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:25:26.657971Z","iopub.execute_input":"2025-02-09T13:25:26.658234Z","iopub.status.idle":"2025-02-09T13:25:26.670473Z","shell.execute_reply.started":"2025-02-09T13:25:26.658210Z","shell.execute_reply":"2025-02-09T13:25:26.669507Z"}},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":"# 1.1. TRAINING","metadata":{}},{"cell_type":"code","source":"if retrain:\n    model_folder = '/kaggle/working/models'\n    for fold_id in idx_list:\n        print(f'idx data: {fold_id}')\n\n        data_folder_idx = data_folder + f'/{fold_id}'\n        model_folder_idx = model_folder + f'/{fold_id}'\n\n        if not bool_using_early_stopping:\n            patience=None\n        \n        print(patience)\n        !python '{train_file}' '{rseed}' '{data_folder_idx}' \\\n            '{postfix_tr}' '{postfix_te}' '{model_folder_idx}' \\\n            '{view_list}' '{num_epoch}'  '{lr}'  '{testonly}' \\\n            '{hidden_dim}' '{print_hyper}' \\\n            '{patience}' '{verbose}' \n        print('*'*100)\nelse:\n    model_folder = f'/kaggle/input/{dataset_name}/models'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:25:26.671540Z","iopub.execute_input":"2025-02-09T13:25:26.671868Z","iopub.status.idle":"2025-02-09T13:26:15.446242Z","shell.execute_reply.started":"2025-02-09T13:25:26.671838Z","shell.execute_reply":"2025-02-09T13:26:15.445210Z"}},"outputs":[{"name":"stdout","text":"idx data: 1\n200\n\n            Config:\n                * Reproduce:\n                - Random Seed\n                    = 42\n\n                * Data\n                - Data Folder\n                    = /kaggle/input/tcga-gbm-methxgexcnv-2000-3-omics/TCGA_GBM_GExCNVxMETH_2000_MinMaxScaler/1\n                - Data Train\n                    = _tr\n                - Data Test\n                    = _val\n                - Saved Model Loc\n                    = /kaggle/working/models/1\n                - List Views\n                    = [1, 2, 3]\n\n                *\n                - Num Epoch PostTrain\n                    = 1500\n\n                - Lr Classifier\n                    = 0.0001\n                - Hidden dim\n                    = [1000]\n\n                *\n                - Test Only\n                    = False\n\n                - Patience\n                    = 200\n                - Verbose   \n                    = False\n            \n\nTraining...\n\nTest: Epoch 0\nTest F1 weighted: 0.16270\nTest F1 macro: 0.16071\n\nTest: Epoch 50\nTest F1 weighted: 0.58701\nTest F1 macro: 0.54113\n\nTest: Epoch 100\nTest F1 weighted: 0.71010\nTest F1 macro: 0.66743\n\nTest: Epoch 150\nTest F1 weighted: 0.83263\nTest F1 macro: 0.83315\n\nTest: Epoch 200\nTest F1 weighted: 0.85089\nTest F1 macro: 0.84938\n\nTest: Epoch 250\nTest F1 weighted: 0.86920\nTest F1 macro: 0.86770\n\nTest: Epoch 300\nTest F1 weighted: 0.86920\nTest F1 macro: 0.86770\n\nTest: Epoch 350\nTest F1 weighted: 0.86920\nTest F1 macro: 0.86770\n\nTest: Epoch 400\nTest F1 weighted: 0.86920\nTest F1 macro: 0.86770\nEarly stop at epoch 415th after 200 epochs not increasing score from epoch 215th with best score 0.8895451965375337\n****************************************************************************************************\nidx data: 2\n200\n\n            Config:\n                * Reproduce:\n                - Random Seed\n                    = 42\n\n                * Data\n                - Data Folder\n                    = /kaggle/input/tcga-gbm-methxgexcnv-2000-3-omics/TCGA_GBM_GExCNVxMETH_2000_MinMaxScaler/2\n                - Data Train\n                    = _tr\n                - Data Test\n                    = _val\n                - Saved Model Loc\n                    = /kaggle/working/models/2\n                - List Views\n                    = [1, 2, 3]\n\n                *\n                - Num Epoch PostTrain\n                    = 1500\n\n                - Lr Classifier\n                    = 0.0001\n                - Hidden dim\n                    = [1000]\n\n                *\n                - Test Only\n                    = False\n\n                - Patience\n                    = 200\n                - Verbose   \n                    = False\n            \n\nTraining...\n\nTest: Epoch 0\nTest F1 weighted: 0.15676\nTest F1 macro: 0.16444\n\nTest: Epoch 50\nTest F1 weighted: 0.66125\nTest F1 macro: 0.59602\n\nTest: Epoch 100\nTest F1 weighted: 0.77817\nTest F1 macro: 0.74994\n\nTest: Epoch 150\nTest F1 weighted: 0.82980\nTest F1 macro: 0.81831\n\nTest: Epoch 200\nTest F1 weighted: 0.85075\nTest F1 macro: 0.84537\n\nTest: Epoch 250\nTest F1 weighted: 0.85215\nTest F1 macro: 0.84614\n\nTest: Epoch 300\nTest F1 weighted: 0.86878\nTest F1 macro: 0.86071\n\nTest: Epoch 350\nTest F1 weighted: 0.86878\nTest F1 macro: 0.86071\nEarly stop at epoch 373th after 200 epochs not increasing score from epoch 173th with best score 0.8713793922127256\n****************************************************************************************************\nidx data: 3\n200\n\n            Config:\n                * Reproduce:\n                - Random Seed\n                    = 42\n\n                * Data\n                - Data Folder\n                    = /kaggle/input/tcga-gbm-methxgexcnv-2000-3-omics/TCGA_GBM_GExCNVxMETH_2000_MinMaxScaler/3\n                - Data Train\n                    = _tr\n                - Data Test\n                    = _val\n                - Saved Model Loc\n                    = /kaggle/working/models/3\n                - List Views\n                    = [1, 2, 3]\n\n                *\n                - Num Epoch PostTrain\n                    = 1500\n\n                - Lr Classifier\n                    = 0.0001\n                - Hidden dim\n                    = [1000]\n\n                *\n                - Test Only\n                    = False\n\n                - Patience\n                    = 200\n                - Verbose   \n                    = False\n            \n\nTraining...\n\nTest: Epoch 0\nTest F1 weighted: 0.19874\nTest F1 macro: 0.19935\n\nTest: Epoch 50\nTest F1 weighted: 0.57933\nTest F1 macro: 0.52365\n\nTest: Epoch 100\nTest F1 weighted: 0.68589\nTest F1 macro: 0.63938\n\nTest: Epoch 150\nTest F1 weighted: 0.79481\nTest F1 macro: 0.78310\n\nTest: Epoch 200\nTest F1 weighted: 0.83663\nTest F1 macro: 0.83742\n\nTest: Epoch 250\nTest F1 weighted: 0.80034\nTest F1 macro: 0.80173\n\nTest: Epoch 300\nTest F1 weighted: 0.78277\nTest F1 macro: 0.78296\n\nTest: Epoch 350\nTest F1 weighted: 0.80230\nTest F1 macro: 0.79996\nEarly stop at epoch 370th after 200 epochs not increasing score from epoch 170th with best score 0.8366281213340038\n****************************************************************************************************\nidx data: 4\n200\n\n            Config:\n                * Reproduce:\n                - Random Seed\n                    = 42\n\n                * Data\n                - Data Folder\n                    = /kaggle/input/tcga-gbm-methxgexcnv-2000-3-omics/TCGA_GBM_GExCNVxMETH_2000_MinMaxScaler/4\n                - Data Train\n                    = _tr\n                - Data Test\n                    = _val\n                - Saved Model Loc\n                    = /kaggle/working/models/4\n                - List Views\n                    = [1, 2, 3]\n\n                *\n                - Num Epoch PostTrain\n                    = 1500\n\n                - Lr Classifier\n                    = 0.0001\n                - Hidden dim\n                    = [1000]\n\n                *\n                - Test Only\n                    = False\n\n                - Patience\n                    = 200\n                - Verbose   \n                    = False\n            \n\nTraining...\n\nTest: Epoch 0\nTest F1 weighted: 0.12803\nTest F1 macro: 0.14020\n\nTest: Epoch 50\nTest F1 weighted: 0.62614\nTest F1 macro: 0.56707\n\nTest: Epoch 100\nTest F1 weighted: 0.72909\nTest F1 macro: 0.69438\n\nTest: Epoch 150\nTest F1 weighted: 0.76835\nTest F1 macro: 0.74950\n\nTest: Epoch 200\nTest F1 weighted: 0.77300\nTest F1 macro: 0.76384\n\nTest: Epoch 250\nTest F1 weighted: 0.79188\nTest F1 macro: 0.78021\n\nTest: Epoch 300\nTest F1 weighted: 0.81398\nTest F1 macro: 0.80843\n\nTest: Epoch 350\nTest F1 weighted: 0.79188\nTest F1 macro: 0.78021\n\nTest: Epoch 400\nTest F1 weighted: 0.79675\nTest F1 macro: 0.79230\n\nTest: Epoch 450\nTest F1 weighted: 0.81433\nTest F1 macro: 0.81372\n\nTest: Epoch 500\nTest F1 weighted: 0.81433\nTest F1 macro: 0.81372\n\nTest: Epoch 550\nTest F1 weighted: 0.81433\nTest F1 macro: 0.81372\nEarly stop at epoch 573th after 200 epochs not increasing score from epoch 373th with best score 0.8321468654801988\n****************************************************************************************************\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"# 1.2. Load trained models and check accuracy phase 1","metadata":{}},{"cell_type":"code","source":"evaluate_model(_type_data='tr')\nevaluate_model(_type_data='val')\nevaluate_model(_type_data='te')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:15.447686Z","iopub.execute_input":"2025-02-09T13:26:15.447939Z","iopub.status.idle":"2025-02-09T13:26:16.759794Z","shell.execute_reply.started":"2025-02-09T13:26:15.447910Z","shell.execute_reply":"2025-02-09T13:26:16.757721Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-9859415efdc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_type_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_type_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_type_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'te'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-40-860a7025727a>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(bool_report, _type_data)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcur_model_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{model_folder}/{idx}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mcur_data_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{data_folder}/{idx}/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_data_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_model_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0m_data_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-38-c5dfe1ea0717>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(data_folder, model_folder)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_model_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m# ---- Done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/nckh_2025/xai/utils.py\u001b[0m in \u001b[0;36mload_model_dict\u001b[0;34m(folder, model_dict)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;31m#            print(\"Module {:} loaded!\".format(module))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mmodel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda:{:}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WARNING: Module {:} from model_dict is not loaded!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# copy state_dict so _load_from_state_dict can modify it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_metadata'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 779\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleAttributeError\u001b[0m: 'MMDynamic' object has no attribute 'copy'"],"ename":"ModuleAttributeError","evalue":"'MMDynamic' object has no attribute 'copy'","output_type":"error"}],"execution_count":42},{"cell_type":"markdown","source":"# MODULE 2: Integrated Gradient","metadata":{}},{"cell_type":"code","source":"biomarkers_folder = '/kaggle/working/biomarkers/' + COHORT\npostfix_tr = '_tr'\npostfix_te = '_val'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.760682Z","iopub.status.idle":"2025-02-09T13:26:16.761064Z","shell.execute_reply":"2025-02-09T13:26:16.760886Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2.1. Baselines for IG","metadata":{}},{"cell_type":"code","source":"# Load dict mapping name of {int_id_label:label_name} that int_id_label start from 0 and {int_id_omic:omic_name} that int_id_omic start from 1\nloc_file_json_id_label = data_folder + '/1/dct_index_subtype.json'\nloc_file_json_id_omic = data_folder + '/1/dict_id_omics.json'\n\nwith open(loc_file_json_id_label) as file_json_id_label:\n    dct_LABEL_MAPPING_NAME = json.load(file_json_id_label)\n    dct_LABEL_MAPPING_NAME = {int(k): v for k,v in dct_LABEL_MAPPING_NAME.items()} # convert str number key to int\n# print(\"\\n{int_id_label:label_name} = \", dct_LABEL_MAPPING_NAME)\n\nwith open(loc_file_json_id_omic) as file_json_id_omic:\n    dct_OMIC_MAPPING_NAME = json.load(file_json_id_omic)\n    dct_OMIC_MAPPING_NAME = {int(k): v for k,v in dct_OMIC_MAPPING_NAME.items()} # convert str number key to int\n# print(\"\\n{int_id_omic:omic_name} = \", dct_OMIC_MAPPING_NAME)\n\n\n\n###############\n\n# may be fixed\nn_folds = num_models # fold id start from 1\ntype_data = 'tr' # fixed\nfold_start_id = 1\nlist_fold_id = list(range(n_folds+fold_start_id)[fold_start_id:])\n\n\ndict_fold_dict_baseline = {}\n\nfor fold_id in list_fold_id:\n    data_folder_idx = data_folder + f'/{fold_id}'\n#     print(f'\\n*Using data of fold_id= \"{fold_id}\" with data type = \"{type_data}\" for each omic (total \"{len(dct_OMIC_MAPPING_NAME)}\" type(s) of omic) in folder \"{data_folder_idx}\" to create baseline')\n    ##############\n    tmp_label = pd.read_csv(os.path.join(data_folder_idx, f'labels_{type_data}.csv'), header=None)\n\n    tmp_dict_omic_pd_data = {id_omic: pd.read_csv(os.path.join(data_folder_idx, f'{str(id_omic)}_{type_data}.csv'), header=None) for id_omic in dct_OMIC_MAPPING_NAME.keys()}\n    tmp_dict_omic_shape = {id_omic: tmp_dict_omic_pd_data[id_omic].shape[1] for id_omic in dct_OMIC_MAPPING_NAME.keys()} # number of features each omic\n    \n    tmp_dict_omic_pd_data_w_label = {id_omic: tmp_dict_omic_pd_data[id_omic].copy(deep=True) for id_omic in dct_OMIC_MAPPING_NAME.keys()}\n    for id_omic in tmp_dict_omic_pd_data_w_label.keys():\n        tmp_dict_omic_pd_data_w_label[id_omic]['subtype'] = tmp_label[0]\n\n    tmp_dict_baseline= {}\n    \n    #############################\n    tmp_dict_baseline['zeros']= tuple(torch.zeros((1,tmp_dict_omic_shape[id_omic])\n                                              , dtype=torch.float32) for id_omic in dct_OMIC_MAPPING_NAME.keys())\n    tmp_dict_baseline['micro_means']= tuple(torch.tensor(tmp_dict_omic_pd_data[id_omic].mean(axis=0).values.reshape(1,-1)\n                                                         , dtype=torch.float32) for id_omic in dct_OMIC_MAPPING_NAME.keys())\n    tmp_dict_baseline['macro_means']= tuple(torch.tensor(tmp_dict_omic_pd_data_w_label[id_omic].groupby('subtype').mean().mean(axis=0).values.reshape(1,-1)\n                                                         , dtype=torch.float32) for id_omic in dct_OMIC_MAPPING_NAME.keys())\n    ##########################################################\n\n    tmp_dict_baseline['dict_default_micro_means']= {}\n    \n    tmp_list_of_list_exclude_cursor_label_id = [sorted(list(set(dct_LABEL_MAPPING_NAME.keys()) - set([label_id]))) for label_id in dct_LABEL_MAPPING_NAME.keys()]\n    tmp_dict_baseline['dict_default_macro_means']= {}\n    \n    for label_id in dct_LABEL_MAPPING_NAME.keys():\n        tmp_dict_baseline['dict_default_macro_means'][label_id] = tuple(\n            torch.tensor(\n                tmp_dict_omic_pd_data_w_label[id_omic].groupby('subtype').mean().loc[tmp_list_of_list_exclude_cursor_label_id[label_id]].mean(axis=0).values.reshape(1,-1)\n                ,dtype=torch.float32\n            ) for id_omic in dct_OMIC_MAPPING_NAME.keys()\n        )\n        \n        tmp_dict_baseline['dict_default_micro_means'][label_id] = tuple(\n            torch.tensor(\n                tmp_dict_omic_pd_data_w_label[id_omic][\n                    tmp_dict_omic_pd_data_w_label[id_omic]['subtype'] != label_id # filter to exclude row have label is {label_id}\n                ].loc[:,tmp_dict_omic_pd_data_w_label[id_omic].columns != 'subtype' # then filter to exclude column of label before cal mean for all columns\n                     ].mean(axis=0).values.reshape(1,-1)\n                ,dtype=torch.float32\n            ) for id_omic in dct_OMIC_MAPPING_NAME.keys()\n        )\n    ##########################################################\n     \n    # Final assign\n    dict_fold_dict_baseline[fold_id] = tmp_dict_baseline\n    \n    print(f'For fold_id = \"{fold_id}\" Done create all baseline type/with name:\\n\\tin {list(tmp_dict_baseline.keys())}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.762217Z","iopub.status.idle":"2025-02-09T13:26:16.762657Z","shell.execute_reply":"2025-02-09T13:26:16.762445Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_attribution_scores_for_folder(input, _label, cur_data_folder, idx_model, type_base_line, _n_steps=100):\n    \n    # Initialize Integrated Gradients with the custom model predictor\n    # ig = IntegratedGradients(lambda *inputs: custom_logit_predictor(*inputs, data_folder=cur_data_folder))\n    ig = GradientShap(lambda *inputs: custom_logit_predictor(*inputs, data_folder=cur_data_folder))\n\n    number_of_samples = len(_label)\n    \n    # Calculate attribute scores by batch data to avoid running out of memory\n    # 200 is the maximum (approximate) number of samples that will not cause run out of memory with this TCGA BRCA data (on Train data)\n    max_samples_per_batch = 100\n    # Get list end of index to split data into batches\n    list_end_index = [max_samples_per_batch*times \n                      for times in range(1,int(np.ceil(number_of_samples/max_samples_per_batch)))\n                     ] + [number_of_samples]\n    \n    attr = {}\n    for subtype_idx, subtype in enumerate(LABEL_MAPPING_NAME):\n        #----------------------------------------\n        start = 0\n#             print(f'\\n\\t\\t<> Calculate attribution scores with subtype: \"{subtype}\":')\n\n\n        if type_base_line[:4] == 'dict':\n#                 print(f'\\t\\t Type baseline:\\n\\t\\t  [{type_base_line}] -> Special baseline for each subtype')\n            baseline = dict_fold_dict_baseline[idx_model][type_base_line][subtype_idx]\n        else:\n#                 print(f'\\t\\t Type baseline:\\n\\t\\t  [{type_base_line}]')\n            baseline = dict_fold_dict_baseline[idx_model][type_base_line]\n        if cuda:\n            baseline = tuple(tensor_i.cuda() for tensor_i in baseline)\n#             print(f'\\t\\t Model pred score:\\n\\t\\t  {custom_logit_predictor(*baseline, data_folder=cur_data_folder).detach().cpu().numpy()} -> SUM={torch.sum(custom_logit_predictor(*baseline, data_folder=cur_data_folder)).detach().cpu().numpy()}')\n\n        for end in list_end_index:\n#                 print(f'\\t\\t\\t:samples from iloc {start} to {end}:')\n\n            input_tensor = tuple(input_omic[start:end].requires_grad_() for input_omic in input)\n\n            # attr_temp, delta_temp = ig.attribute(input_tensor,\n            #                                      baselines=baseline,\n            #                                      target= subtype_idx, return_convergence_delta=True,\n            #                                     n_steps=_n_steps)\n\n            # GradientSHAP\n            attr_temp, delta_temp = ig.attribute(input_tensor,\n                                                 baselines=baseline,\n                                                 target= subtype_idx, return_convergence_delta=True,)\n            \n            # concatenate genes attribute score for multi-omics data\n            attr_temp = np.concatenate(tuple(attr_temp[idx_atr].detach().cpu().numpy() for idx_atr in range(len(attr_temp))), axis=1)\n            if start == 0:\n                attr[subtype] =  attr_temp\n            else:\n                attr[subtype] = np.concatenate((attr[subtype],attr_temp),axis=0)\n            start=end\n#             print(f'\\t\\t\\t: [Delta temp: min={delta_temp.min()}, max={delta_temp.max()}, mean={delta_temp.mean()}, std={delta_temp.std()}]\\n')\n\n    return attr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.763580Z","iopub.status.idle":"2025-02-09T13:26:16.763981Z","shell.execute_reply":"2025-02-09T13:26:16.763810Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2.2. Calculate and Sort IG's score of each feature from: train data + trained model","metadata":{}},{"cell_type":"code","source":"topn=10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.764809Z","iopub.status.idle":"2025-02-09T13:26:16.765177Z","shell.execute_reply":"2025-02-09T13:26:16.764995Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def cal_feat_imp(num_models, type_base_line ='zeros',_n_steps=100, type_data='tr'):\n    \n    loc_file_json_id_omic = data_folder + '/1/dct_index_subtype.json'\n    with open(loc_file_json_id_omic) as file_json_id_omic:\n        dct_LABEL_MAPPING_NAME = json.load(file_json_id_omic)\n    LABEL_MAPPING_NAME = dct_LABEL_MAPPING_NAME.values() \n    \n    start_time=datetime.now()\n    \n    dct_feat_imp_by_models = {}\n    for idx_model in range(1,num_models+1):\n        data_folder_idx = data_folder + f'/{idx_model}'\n        model_folder_idx = model_folder + f'/{idx_model}'\n        added_softmax = True\n        \n        # loading dataset\n        _data_list=[]\n        _label = np.loadtxt(os.path.join(data_folder_idx, f\"labels_{type_data}.csv\"), delimiter=',').astype(int)\n\n        for i in view_list:\n            _data_loc = os.path.join(data_folder_idx, str(i)+ f\"_{type_data}.csv\")\n            _data_list.append(np.loadtxt(_data_loc, delimiter=','))\n        _tensor_data_list = tuple(torch.tensor(np_arr,dtype=torch.float32).to(device) for np_arr in _data_list)\n\n        gene_name = []\n        for v in view_list:\n            df = pd.read_csv(os.path.join(data_folder_idx, str(v)+\"_featname.csv\"), header=None)    \n            gene_name.extend(df[0].values.tolist())\n            # DONE USE THIS: gene_name.extend(df[0].str.split(r'\\|').str[0].values.tolist()) # only used when want combined same features that first part before | symbol if exist\n\n        \n        ## load models weights\n        load_model(data_folder_idx, model_folder_idx)\n        \n        #---------------------------------------------------------------------\n\n        # Calculate attribute score:\n        attr = calculate_attribution_scores_for_folder(_tensor_data_list, _label, data_folder_idx, idx_model, type_base_line, _n_steps)\n        \n        # ------------------------------\n        lst_ordered_subtype = list(attr.keys())\n        stack_subtype_attr = np.stack(tuple(attr[subtype] for subtype in lst_ordered_subtype))\n        feat_imp_like_each_class = np.abs(stack_subtype_attr).mean(axis=1)\n        feat_imp_like = feat_imp_like_each_class.sum(axis=0)\n        \n        dct_feat_imp_by_models[idx_model] = feat_imp_like\n    \n    # along models\n    final_feat_imp_like = np.mean(list(dct_feat_imp_by_models.values()), axis=0)\n\n    idx_sorted_desc_mean_abs_sum = np.argsort(final_feat_imp_like)[::-1] # Note hien tai dang khong quan tam examples nao dung, example nao du doan sai nhu mot so cach o duoi day\n    sorted_score_feat_imp_like = final_feat_imp_like[idx_sorted_desc_mean_abs_sum]\n    rank_imp_feats_by_abs_mean_sum_without_combine_same_gene_name = list(np.array(gene_name)[idx_sorted_desc_mean_abs_sum])\n    pd_rank_by_abs_mean_sum = pd.DataFrame({'gene_name': rank_imp_feats_by_abs_mean_sum_without_combine_same_gene_name}) #, 'score':sorted_score_feat_imp_like\n    print(f'\\t=>Result (Here print out the top {topn} biomakers with highest values):')\n    \n    end_time=datetime.now()\n    print(f'\\tRun in {end_time-start_time}')\n    \n    display(pd_rank_by_abs_mean_sum.head(topn))\n    return pd_rank_by_abs_mean_sum","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.766150Z","iopub.status.idle":"2025-02-09T13:26:16.766714Z","shell.execute_reply":"2025-02-09T13:26:16.766426Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def export_biomarker_file(list_concerned_type_baseline, list_concerned_type_data, list_concerned_num_models, biomarkers_folder, _n_steps=100):\n    list_biomakers_file_loc = []\n    print('_'*100)\n    print(f'Biomarker Discovery for {biomarkers_folder.split(\"/\")[-1]} cohort:')\n    pd_results = {}\n    for type_base_line in list_concerned_type_baseline:\n        pd_results[type_base_line] = {}\n        for type_data in list_concerned_type_data:\n            pd_results[type_base_line][type_data] = {}\n            for num_models in list_concerned_num_models:\n                \n                pd_results[type_base_line][type_data][num_models] = cal_feat_imp(num_models=num_models,type_base_line=type_base_line,_n_steps=n_steps, type_data= type_data)\n\n                if not os.path.exists(biomarkers_folder):\n                    os.makedirs(biomarkers_folder)\n                    \n                biomakers_file_loc = biomarkers_folder + f'/IG_{type_base_line}_{type_data}_{num_models}_{data_folder.split(\"/\")[-1]}.csv'\n                pd_results[type_base_line][type_data][num_models][['gene_name']].to_csv(biomakers_file_loc, index=False)\n                list_biomakers_file_loc.append(biomakers_file_loc)\n\n    print()\n    return list_biomakers_file_loc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.767849Z","iopub.status.idle":"2025-02-09T13:26:16.768371Z","shell.execute_reply":"2025-02-09T13:26:16.768115Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# list_concerned_type_baseline = ['zeros', 'micro_means', 'macro_means', 'dict_default_micro_means', 'dict_default_macro_means']\nlist_concerned_type_baseline = ['zeros']\nlist_concerned_type_data = ['tr']\nlist_concerned_num_models = [num_models]\n\nn_steps=100\n\nlist_biomakers_file_loc = export_biomarker_file(list_concerned_type_baseline, list_concerned_type_data, list_concerned_num_models, biomarkers_folder, n_steps)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.769539Z","iopub.status.idle":"2025-02-09T13:26:16.770093Z","shell.execute_reply":"2025-02-09T13:26:16.769831Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2.3. MOGONET(NO IG)","metadata":{}},{"cell_type":"code","source":"if Run_MMD:\n    biomarker_file_name = f'mogonet_full_top_biomarkers_sorted_desc_score_{num_models}models.csv'\n    main_biomarker_mogonet = '/kaggle/working/nckh_2025/xai/main_biomarker.py'\n\n    start_time=datetime.now()\n    print(main_biomarker_mogonet)\n    !python '{main_biomarker_mogonet}' '{data_folder}' '{model_folder}' '{dim_he_list}' '{view_list}' '{num_models}' '{postfix_tr}' '{postfix_te}' '{biomarkers_folder}' '{biomarker_file_name}' '{topn}'\n    print(f'\\t=>Result (Here print out the top {topn} biomakers with highest values):')\n    end_time=datetime.now()\n    print(f'\\tRun in {end_time-start_time}')","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.771266Z","iopub.status.idle":"2025-02-09T13:26:16.771910Z","shell.execute_reply":"2025-02-09T13:26:16.771533Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. PHASE 3","metadata":{}},{"cell_type":"code","source":"# Threshold to take number of genes (biomarkers) per subtype\nprint(dct_OMIC_MAPPING_NAME)\nROOT_DATA_FOLDER = f'/kaggle/input/{dataset_name}/{COHORT}/train_test_split_org/'\nRANDOM_STATE = 42\n\nLIST_OMICS = list(dct_OMIC_MAPPING_NAME.values())\nprint(LIST_OMICS)\nLIST_OMICS_ID = np.arange(1,len(LIST_OMICS)+1,1)\n\n# Single omic or Multi-omics| to run experiments\nLIST_EXP_OMICS = ['_'.join(LIST_OMICS)]\nprint(LIST_EXP_OMICS)\n\n\nLIST_TYPE_DATA = ['train', 'test']\nDATA_FOLDER = {'train': ROOT_DATA_FOLDER,\n              'test': ROOT_DATA_FOLDER}\n\n\nloc_file_json_id_label = data_folder + '/1/dct_index_subtype.json'\nwith open(loc_file_json_id_label) as file_json_id_label:\n    dct_LABEL_MAPPING_NAME = json.load(file_json_id_label)\n    dct_LABEL_MAPPING_NAME = {int(k): v for k,v in dct_LABEL_MAPPING_NAME.items()}\nORIGINAL_MAPPING_NAME = dct_LABEL_MAPPING_NAME\nprint(ORIGINAL_MAPPING_NAME)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.773173Z","iopub.status.idle":"2025-02-09T13:26:16.773746Z","shell.execute_reply":"2025-02-09T13:26:16.773445Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"BIOMARKERS_RESULT_FOLDER = '/kaggle/working/biomarkers'\nlist_loc_biomarkers = []\nfor dirname, _, filenames in os.walk(BIOMARKERS_RESULT_FOLDER):\n    for filename in filenames:\n        list_loc_biomarkers.append(os.path.join(dirname, filename))\n# print(list_loc_biomarkers)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.774901Z","iopub.status.idle":"2025-02-09T13:26:16.775442Z","shell.execute_reply":"2025-02-09T13:26:16.775175Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3.1. Check overlap with other genes","metadata":{}},{"cell_type":"code","source":"direct_evidence_gene_list = [\n    \"EGFR\", \"MGMT\", \"CXCL8\", \"H2AX\", \"VEGFA\", \"EGF\", \"MMP2\", \"HIF1A\", \"MMP9\", \"IL1B\",\n    \"MYC\", \"CDK6\", \"MTOR\", \"HES1\", \"FN1\", \"NDRG1\", \"CTSB\", \"PTK2\", \"CD9\", \"PROM1\",\n    \"WT1\", \"FAT1\", \"HEY1\", \"DUSP6\", \"NCOR1\", \"NOTCH1\", \"BMI1\", \"BHLHE40\", \"TP53BP1\", \"PIM1\",\n    \"MET\", \"JAG1\", \"CSTA\", \"CHI3L1\", \"APC\", \"CTSK\", \"NOTCH2\", \"FAM83D\", \"GSTT1\", \"FOSL2\",\n    \"GDNF\", \"TES\", \"PRKN\", \"SUZ12\", \"CSTB\", \"ZBTB7A\", \"BCHE\", \"RUNX1\", \"CCNH\", \"LRRC59\",\n    \"PML\", \"POLK\", \"SRRT\", \"RUNX3\", \"CTNND2\", \"TMEM135\", \"MDM4\", \"H3-3A\", \"BRD2\", \"TRMT11\",\n    \"NF1\", \"HOXD10\", \"GRIK2\", \"JAG2\", \"BRD4\", \"LTBP4\", \"MACIR\", \"NOTCH3\", \"LZTR1\", \"H3C2\",\n    \"SLC22A10\", \"DEUP1\", \"SEPTIN14\", \"TGM2\", \"TNFSF10\", \"IL2\", \"RECK\", \"IFNA2\"\n]\ntopn_lst = [50, 100, 200, 400]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.776593Z","iopub.status.idle":"2025-02-09T13:26:16.777143Z","shell.execute_reply":"2025-02-09T13:26:16.776887Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = []\n\nfor file_loc in list_loc_biomarkers:\n    file_name = file_loc.split('/')[-1]\n    ig_biomarkers = pd.read_csv(file_loc).iloc[:, 0].str.split(r'\\|').str[0].values.tolist()\n    baseline_name = '-'.join(file_name.split('_')[:-7])\n    for i in topn_lst:\n        intersect_direct = sorted(list(set(direct_evidence_gene_list).intersection(set(ig_biomarkers[:i]))))\n        intersect_direct_str = ', '.join(intersect_direct)\n        data.append([baseline_name, i, intersect_direct_str]) #, intersect_reference, intersect_inference])\n\ndf = pd.DataFrame(data, columns=['Baseline', 'TopN', 'Intersect with Direct Evidence Gene List']) #, 'Intersect with Top Reference Gene List', 'Intersect with Top Inference Gene List'])\n\n# Print table\npd.set_option('display.max_colwidth', None)\ndisplay(df)\n\ndf.to_csv(\"/kaggle/working/genes_overlap.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.778303Z","iopub.status.idle":"2025-02-09T13:26:16.778735Z","shell.execute_reply":"2025-02-09T13:26:16.778512Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3.2. TEST WITH CLASSIC ML ALGO","metadata":{}},{"cell_type":"code","source":"# pd.set_option('display.max_columns', None)\n# pd.set_option('display.expand_frame_repr', False)\n# pd.set_option('max_colwidth', None)\ndef printmd(string, color=None):\n    colorstr = \"<span style='color:{}'>{}</span>\".format(color, string)\n    display(Markdown(colorstr))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.779482Z","iopub.status.idle":"2025-02-09T13:26:16.779886Z","shell.execute_reply":"2025-02-09T13:26:16.779712Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def display_classification_report(\n    n_class,\n    label,\n    pred,\n    label_mapping_name,\n    cmap=\"Blues\",\n    fmt=\".2%\",\n    annot=True,\n    path=None,  # str path to save fig. If not None\n    shown=True,\n):\n\n    clf_report = classification_report(\n        label,\n        pred,\n        target_names=label_mapping_name,\n        digits=4,\n        zero_division=0,\n        output_dict=True,\n    )\n\n    clf_df = pd.DataFrame(clf_report)\n    clf_df.loc[[\"precision\", \"recall\"], \"accuracy\"] = np.nan\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    fig.set_figwidth(12)\n    ConfusionMatrixDisplay(\n        confusion_matrix(label, pred), display_labels=label_mapping_name\n    ).plot(cmap=cmap, ax=ax1)\n    sns.heatmap(\n        clf_df.iloc[:-1, :].T, annot=annot, cmap=cmap, robust=True, ax=ax2, fmt=fmt\n    )\n    if path is not None:\n        fig.savefig(path, dpi=300)\n    if shown:\n        plt.show()\n    else:\n        plt.close(fig)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.780670Z","iopub.status.idle":"2025-02-09T13:26:16.781006Z","shell.execute_reply":"2025-02-09T13:26:16.780850Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tuning_and_eval(gridcvs, X_train, y_train, X_test, y_test,\n                    scoring, refit, is_binary_problem,\n                    result_on_dataset, rank_hparams_info):\n    assert 'test' in result_on_dataset\n    assert isinstance(rank_hparams_info, bool)\n    ###\n    lst_dct_result = [] # to return\n    ###\n\n    start=datetime.now()\n    X = {}\n    y = {}\n    X['train'] = X_train\n    X['test'] = X_test\n    y['train'] = y_train\n    y['test'] = y_test\n\n    for model_name, gs_est in sorted(gridcvs.items()):\n        ###\n        sub_result = {}\n        sub_result['model'] = model_name\n        ###\n\n        start_individual_type_model = datetime.now()\n        gs_est.fit(X['train'],y['train'])\n\n        ###\n        sub_result['best_params'] = gs_est.best_params_\n        ###\n\n        ###\n        sub_result[f'best_tuning_{refit}'] = gs_est.best_score_ * 100\n        sub_result['best_tuning_std'] = gs_est.cv_results_[f'std_test_{refit}'][gs_est.best_index_] * 100\n        ###\n\n        if rank_hparams_info:\n            select_result_cols = []\n            for metric in scoring:\n                select_result_cols.extend(['rank_test_'+metric,'mean_test_'+ metric, 'std_test_'+metric])\n            select_result_cols.extend(['params'])\n\n            dataframe_results = pd.DataFrame(gs_est.cv_results_).loc[:,select_result_cols].sort_values(by=f'mean_test_{refit}',ascending=False)\n            display(dataframe_results[:10])\n\n        for type_data in result_on_dataset:\n            y_predict = gs_est.predict(X[type_data])\n\n            acc = accuracy_score(y_true=y[type_data], y_pred=y_predict)\n\n            ###\n            sub_result[f'{type_data}_acc'] = acc * 100\n            ###\n\n            if is_binary_problem:\n                f1 = f1_score(y_true=y[type_data], y_pred=y_predict,average='binary')\n                y_score = gs_est.predict_proba(X[type_data])[:, 1]\n                roc_auc = roc_auc_score(y_true=y[type_data], y_score=y_score)\n\n                ###\n                sub_result[f'{type_data}_f1'] = f1 * 100\n                ###\n\n                ###\n                sub_result[f'{type_data}_roc_auc'] = roc_auc * 100\n                ###\n            else:\n                f1_macro = f1_score(y_true=y[type_data], y_pred=y_predict,average='macro')\n                f1_weighted = f1_score(y_true=y[type_data], y_pred=y_predict,average='weighted')\n\n                ###\n                sub_result[f'{type_data}_f1_macro'] = f1_macro * 100\n                ###\n\n                ###\n                sub_result[f'{type_data}_f1_weighted'] = f1_weighted * 100\n                ##\n\n            ###\n            lst_dct_result.append(sub_result)\n            ###\n\n#             pd_cfm = pd.crosstab(\n#                 y[type_data]\n#                 , y_predict\n#                 , margins=True\n#                 , rownames=['True label']\n#                 , colnames=['Pred label']\n#             )\n            \n#             for label in ORIGINAL_MAPPING_NAME.values():\n#                 if label not in pd_cfm.index:\n#                     pd_cfm.loc[label] = 0\n#                 if label not in pd_cfm.columns:\n#                     pd_cfm[label] = 0\n\n#             pd_cfm = pd_cfm.reindex(index=list(ORIGINAL_MAPPING_NAME.values()) + ['All'], \n#                                     columns=list(ORIGINAL_MAPPING_NAME.values()) + ['All'])\n\n#             display(pd_cfm)\n            \n            folder_save_fig = f\"/kaggle/working/cfm/{biomarker_file.split('/')[-1].split('.')[-2]}/{model_name}\"\n            if not os.path.exists(folder_save_fig):\n                os.makedirs(folder_save_fig)\n            path_save_fig = f\"{folder_save_fig}/top{threshold}.png\"\n            display_classification_report(n_class=len(ORIGINAL_MAPPING_NAME)\n                                          , label=y[type_data]\n                                          , pred= y_predict\n                                          , label_mapping_name=ORIGINAL_MAPPING_NAME.values()\n                                          , path=path_save_fig\n                                          , shown=False\n                                         )\n    return lst_dct_result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.782083Z","iopub.status.idle":"2025-02-09T13:26:16.782472Z","shell.execute_reply":"2025-02-09T13:26:16.782292Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def validate_biomarker(dict_X_train, dict_y_train, dict_X_test, dict_y_test,\n                       omics=['GE_CNA', 'GE','CNA'], random_state = RANDOM_STATE,\n                       result_on_dataset = ['train','test'], rank_hparams_info = True,\n                       is_binary_problem=False):\n    assert 'test' in result_on_dataset\n    assert isinstance(rank_hparams_info, bool)\n    ###\n    validate_biomarker_result = []\n    ###\n    scoring = None\n    refit= None\n    if is_binary_problem:\n        scoring = ['f1','accuracy','roc_auc']\n        refit = 'f1'\n    else: \n        scoring = ['f1_macro','f1_weighted', 'accuracy']\n        refit = 'f1_macro'\n\n    # Initializing classifiers\n    clf1 = LogisticRegression(random_state=random_state, max_iter=10000, n_jobs=-1)\n\n    # Binary case, probability = True to cal ROC_AUC, slowdown k-fold....\n    clf2 = SVC(random_state=random_state, probability=is_binary_problem)\n\n    clf3 = RandomForestClassifier(random_state=random_state,n_jobs=-1)\n\n    # Building the pipelines\n    pipe1 = Pipeline([('std', 'passthrough'),\n                      ('clf1', clf1)])\n\n    pipe2 = Pipeline([('std', 'passthrough'),\n                      ('clf2', clf2)])\n\n#     # only apply std to mRNA data/ BY index mRNA| ignore or passthorough not to\n#     # apply standard scaler to remaining index corresponding to CNA data\n#     column_trans = ColumnTransformer(\n#         [('scaler', StandardScaler(),list(range(len(GENE['mRNA']))))]\n#         ,remainder='passthrough')\n    # Setting up the parameter grids\n    param_grid1 = [{\n                    'std': [MinMaxScaler()],\n                    'clf1__penalty': ['l2'],\n                    'clf1__multi_class':[\"multinomial\"],\n                    'clf1__solver':[\"newton-cg\"],\n                    'clf1__class_weight': [\"balanced\"],\n                    'clf1__C': np.power(10., np.arange(-4, 3)),\n                    }]\n\n    param_grid2 = [{\n                    'std': [MinMaxScaler()],\n                    'clf2__kernel': ['rbf'],\n                    'clf2__class_weight': [\"balanced\"],\n                    'clf2__C': np.power(10., np.arange(-4, 3)),\n                    'clf2__gamma': list(np.power(10., np.arange(-4, 0))) + ['scale']\n                    }]\n\n    param_grid3 = [{'n_estimators': [50, 100, 150],\n                    'max_features': [\"sqrt\"],\n                    'max_depth' : list(range(1, 10)) + [None],\n                    'criterion' :[\"gini\"],\n                    'class_weight': [\"balanced\", \"balanced_subsample\"]}]\n\n    # Setting up multiple GridSearchCV objects, 1 for each algorithm\n    gridcvs = {}\n#     cv = RepeatedStratifiedKFold(n_splits=4, n_repeats=10, random_state=random_state)\n    cv = RepeatedStratifiedKFold(n_splits=4, n_repeats=5, random_state=random_state)\n\n    train_options = zip(\n                        (param_grid1,\n                         param_grid2,\n                         param_grid3,\n                        ),\n                        (pipe1,\n                         pipe2,\n                         clf3,\n                        ),\n                        ('1_Softmax',\n                         '2_SVM',\n                         '3_RandomForest',\n                        )\n                       )\n\n    for pgrid, est, model_name in train_options:\n        gcv = GridSearchCV(estimator=est,\n                           param_grid=pgrid,\n                           scoring=scoring,\n                           n_jobs=-1,\n                           cv=cv,\n                           verbose=0,\n                           refit=refit)\n        gridcvs[model_name] = gcv\n\n    for omic in omics:\n#         print('-'*100)\n#         printmd(f'Validate on {omic} data:\\n', color=\"red\")\n\n        X_train = dict_X_train[omic]\n        y_train = np.array(dict_y_train[omic], dtype=np.int16)\n#         print('Train dist: ', np.unique(y_train, return_counts=True ))\n\n        X_test = dict_X_test[omic]\n        y_test = np.array(dict_y_test[omic], dtype=np.int16)\n#         print('Test dist', np.unique(y_test, return_counts=True ),'\\n')\n\n        # run tuning and eval\n        tmp_lst_dct_tuning_result = tuning_and_eval(gridcvs, X_train, y_train, X_test, y_test,\\\n                        scoring, refit,is_binary_problem,\n                        result_on_dataset, rank_hparams_info)\n        ###\n        tmp_base= {'using_omic': omic}\n        validate_biomarker_result.extend([copy.deepcopy(tmp_base) for i in range(len(tmp_lst_dct_tuning_result))])\n        for dct_tmp, dct_val in zip(tmp_lst_dct_tuning_result, validate_biomarker_result):\n            dct_val.update(dct_tmp)\n        ###\n    return validate_biomarker_result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.783471Z","iopub.status.idle":"2025-02-09T13:26:16.783943Z","shell.execute_reply":"2025-02-09T13:26:16.783734Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def validate(biomarker_file, threshold):\n    # init var and para to save the result\n    ###\n    validate_result=[]\n    base_result = {}\n    ###\n#     dct_data_structure = {col: [] for col in lst_cols}\n#     pd_result = pd.DataFrame(columns=lst_cols)\n\n    # Read data\n    dict_df_label = {}\n    dict_df_data = {}\n    # Read data as df and create numpy array data for labeled data\n    for type_data in LIST_TYPE_DATA:\n        # modified\n        dict_df_label[type_data] = pd.read_csv(DATA_FOLDER[type_data] + f'labels_{type_data[:2]}.csv', names=['disease_subtypes'])\n        # ---------------------------------\n\n        # added\n        dict_df_label[type_data]['disease_subtypes'] = dict_df_label[type_data]['disease_subtypes'].astype('int')\n        dict_df_label[type_data].index.names = ['sampleID']\n        \n        dict_df_label[type_data].replace({'disease_subtypes': ORIGINAL_MAPPING_NAME}, inplace=True)\n        # ---------------------------------\n        \n        \n        dict_df_omics = {}\n        dict_narray_omics = {}\n        for omic in LIST_OMICS:\n            # added\n            tmp_feat_name = pd.read_csv(DATA_FOLDER[type_data]+ f'{LIST_OMICS.index(omic)+1}_featname.csv', names=['feat_name'])\n#             tmp_feat_name['feat_name'] = tmp_feat_name['feat_name'].str.split('|').str[0]\n            lst_name = tmp_feat_name.values.reshape(-1).tolist()\n            # ---------------------------------\n\n            # modified\n            dict_df_omics[omic] = pd.read_csv(DATA_FOLDER[type_data] + f'{LIST_OMICS.index(omic)+1}_{type_data[:2]}.csv',names=lst_name)\n            # ---------------------------------\n\n        dict_df_data[type_data] = dict_df_omics\n\n    LABEL_MAPPING_NAME = dict_df_label['train']['disease_subtypes'].astype('category').cat.categories # sorted by alphabetical order\n#     print('LABEL_MAPPING_NAME', LABEL_MAPPING_NAME)\n    \n    # Convert categorical label to numerical label\n    for type_data in LIST_TYPE_DATA:\n        dict_df_label[type_data].loc[:,'disease_subtypes'] = dict_df_label[type_data]['disease_subtypes'].astype('category').cat.codes\n\n    #---------------------------------------------------------------------------------------\n    # Keep only biomarker genes found from TCGA data\n#     print('-'*100)\n#     print('KEEP ONLY BIOMARKER GENES FOUND FROM TCGA DATA')\n    score_genes = pd.read_csv(biomarker_file)\n    score_genes = score_genes.iloc[:threshold, 0]\n    top_genes = list(set(score_genes.to_numpy(copy=True).reshape(-1)))\n#     print(top_genes)\n    top_genes = [gene.upper() for gene in top_genes]\n#     print(f'Top {threshold} from TCGA have {len(top_genes)} unique genes/features:')\n    ###\n    base_result['n_unq_markers'] = len(top_genes)\n    base_result['lst_unq_markers'] = top_genes\n    ###\n    \n    GENE = {}\n    for omic in LIST_OMICS:\n        GENE[omic] = dict_df_data['train'][omic].columns[\n#             dict_df_data['train'][omic].columns.str.upper().str.split(r'\\|').str[0].isin(top_genes)\n            dict_df_data['train'][omic].columns.str.upper().isin(top_genes)\n        ].to_numpy(copy=True).tolist()\n\n#         print(f'\\twith {omic} TOP {threshold}:', len(GENE[omic]))\n        ###\n        base_result[f'n_unq_{omic}'] = len(GENE[omic])\n        base_result[f'lst_unq_{omic}'] = GENE[omic]\n        ###\n    # NOTE THAT DNAmythyl and mRNA maybe have same genename in top gene => incresing num features comparing to num unique genes\n\n        for type_data in LIST_TYPE_DATA:\n            dict_df_data[type_data][omic] = dict_df_data[type_data][omic][GENE[omic]].copy(deep=True)\n    \n    dict_X = {}\n    dict_y = {}\n    for type_data in LIST_TYPE_DATA:\n        dict_X[type_data] = {}\n        dict_y[type_data] = {}\n\n    for type_omic in LIST_EXP_OMICS:\n        if '_' in type_omic:\n#             print(f'Creating data for multi-omics experiment: {type_omic}')\n            list_omics = type_omic.split('_')\n            for type_data in LIST_TYPE_DATA:\n                tuple_data_omics = tuple([dict_df_data[type_data][single_omic] for single_omic in list_omics])\n                dict_X[type_data][type_omic] = np.concatenate(tuple_data_omics, axis=1)\n        else:\n#             print(f'Creating data for single omic experiment: {type_omic}')\n            for type_data in LIST_TYPE_DATA:\n                dict_X[type_data][type_omic] = dict_df_data[type_data][type_omic].to_numpy(copy=True)\n\n        for type_data in LIST_TYPE_DATA:\n            dict_y[type_data][type_omic] = dict_df_label[type_data]['disease_subtypes'].to_numpy(copy=True)\n\n\n    #---------------------------------------------------------------------------------------\n    tmp_lst_dct_validate_biomarker_result = validate_biomarker(dict_X['train'], dict_y['train'], dict_X['test'], dict_y['test'],\n                       omics=LIST_EXP_OMICS, random_state=RANDOM_STATE,\n                       result_on_dataset= ['test'], rank_hparams_info =False,\n                       is_binary_problem = (len(LABEL_MAPPING_NAME)==2))\n    validate_result.extend([copy.deepcopy(base_result) for i in range(len(tmp_lst_dct_validate_biomarker_result))])\n    for dct_tmp, dct_val in zip(tmp_lst_dct_validate_biomarker_result, validate_result):\n        dct_val.update(dct_tmp)\n    return validate_result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.784810Z","iopub.status.idle":"2025-02-09T13:26:16.785141Z","shell.execute_reply":"2025-02-09T13:26:16.784989Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# excluded_files = ['mogonet_full_top_biomarkers_sorted_desc_score_5models.csv']\n# excluded_files = [f'{BIOMARKERS_RESULT_FOLDER}/{COHORT}/'+biomarker_file for biomarker_file in excluded_files]\n\nexcluded_files = [] # evaluation all candidate biomarkers result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.786255Z","iopub.status.idle":"2025-02-09T13:26:16.786599Z","shell.execute_reply":"2025-02-09T13:26:16.786435Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(pd.__version__)\nprint(sklearn.__version__)\nprint(np.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.787744Z","iopub.status.idle":"2025-02-09T13:26:16.788071Z","shell.execute_reply":"2025-02-09T13:26:16.787918Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Ignore ConvergenceWarning\n# warnings.filterwarnings(\"ignore\", category = ConvergenceWarning)\n\n##\nresult = []\nTHRESHOLD_LST = list(range(25, 401, 25))\n##\n\nfor biomarker_file in list_loc_biomarkers:\n    if biomarker_file in excluded_files:\n        continue\n#     print(\"*\"*100)\n    baseline = biomarker_file.split('/')[-1].split('.')[-2]\n    printmd(baseline,'green')\n#         print(biomarker_file)\n\n    start = datetime.now()\n    for threshold in THRESHOLD_LST:\n        ###\n        tmp_result = []\n        base_init_dct_result = {'top': threshold, 'baseline': baseline}\n        tmp_validate_result = validate(biomarker_file,threshold)\n        tmp_result.extend([copy.deepcopy(base_init_dct_result) for i in range(len(tmp_validate_result))])\n        for dct_tmp, dct_val in zip(tmp_validate_result, tmp_result):\n            dct_val.update(dct_tmp)\n\n        result.extend(tmp_result)\n        \n    print(f'Total Time: {datetime.now()-start}')\n        ###\n#         print(f\"Top {threshold} - Using {tmp_result[0]['n_unq_markers']} uniques biomarkers in totals\")\n#         print(tmp_result[0]['lst_unq_markers'])\n#         print('\\n'*2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.788966Z","iopub.status.idle":"2025-02-09T13:26:16.789317Z","shell.execute_reply":"2025-02-09T13:26:16.789152Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3.3. Compare all IG baselines and MOGONET","metadata":{}},{"cell_type":"code","source":"avg_acc_all_models = {}\navg_f1_all_models = {}\nfiltered_results = []\n\nfor res in result:\n#         print(res)\n    model_type = res['model']\n    baseline_type = \"-\".join(res['baseline'].split('_')[:-7])\n    top_n = res['top']\n    accuracy_t = res['test_acc']\n    f1_score_t = res.get('test_f1_macro', res.get('test_f1', 0))\n\n    filtered_results.append({\n        'model_type': model_type,\n        'baseline_type': baseline_type,\n        'top_n': top_n,\n        'accuracy_t': accuracy_t,\n        'f1_score_t': f1_score_t\n    })\n    \n    if model_type not in avg_acc_all_models:\n        avg_acc_all_models[model_type] = {}\n        avg_f1_all_models[model_type] = {}\n\n    if baseline_type not in avg_acc_all_models[model_type]:\n        avg_acc_all_models[model_type][baseline_type] = []\n        avg_f1_all_models[model_type][baseline_type] = []\n\n    avg_acc_all_models[model_type][baseline_type].append((top_n, accuracy_t))\n    avg_f1_all_models[model_type][baseline_type].append((top_n, f1_score_t))\n        \nfor model_type in avg_acc_all_models:\n    for baseline_type in avg_acc_all_models[model_type]:\n        avg_acc_all_models[model_type][baseline_type].sort(key=lambda x: x[0])\n        avg_f1_all_models[model_type][baseline_type].sort(key=lambda x: x[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.790537Z","iopub.status.idle":"2025-02-09T13:26:16.790978Z","shell.execute_reply":"2025-02-09T13:26:16.790782Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_metrics(metrics, metric_name):\n    folder_save_fig = f\"/kaggle/working/cmp\"\n    if not os.path.exists(folder_save_fig):\n        os.makedirs(folder_save_fig)\n    path_save_fig = f'{folder_save_fig}/{metric_name}.png'\n    plt.figure(figsize = (8,4), dpi=300)\n    for baseline_name, values in metrics.items():\n        top_n_list = [item[0] for item in values]\n        metric_values = [item[1] for item in values]\n        plt.plot(top_n_list, metric_values, marker='o', label=baseline_name)\n    plt.title(f'{metric_name} for different baselines and top N features')\n    plt.xlabel('Top N features')\n    plt.ylabel(metric_name)\n    plt.legend(fontsize='small', bbox_to_anchor=(1.05, 1), loc='upper left')    \n    plt.xticks(top_n_list)\n    plt.yticks(list(range(35, 91, 5)))\n    plt.grid(axis='y')\n    plt.tight_layout()\n    plt.savefig(path_save_fig, facecolor='white', edgecolor='white')\n    plt.show()\n    \n# Plot accuracy\nfor model_type in avg_acc_all_models.keys():\n    print('*' * 40, model_type, '*' * 40)\n    plot_metrics(avg_acc_all_models[model_type], f'Accuracy for {model_type}')\n    plot_metrics(avg_f1_all_models[model_type], f'F1 Score for {model_type}')\n    print('\\n\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.791773Z","iopub.status.idle":"2025-02-09T13:26:16.792170Z","shell.execute_reply":"2025-02-09T13:26:16.791982Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convenient for modifying plot\njson_file = \"/kaggle/working/results.json\"\n\nwith open(json_file, mode='w', encoding='utf-8') as file:\n    json.dump(filtered_results, file, ensure_ascii=False, indent=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T13:26:16.793034Z","iopub.status.idle":"2025-02-09T13:26:16.793363Z","shell.execute_reply":"2025-02-09T13:26:16.793210Z"}},"outputs":[],"execution_count":null}]}